下面，我就近期用 LLM 提示词工程做交通流量预测的研究进展进行总结。

[toc]

简要**结论**：提示词工程预测准确率可以达到常规时空模型的中间水平，但是成本上可能不具备实验可行性。应考虑更换小数据集或其他研究方向。

## 实验

### 实验设计

实验配置：

1. 从头手写了一个代码框架，用于调用 LLM API 进行交通流量预测。
2. 用 Deepseek-chat 或 Deepseek-reasoner (深度思考/思维链) 作为预测模型。
3. 数据集使用 PEMS03、PEMS04、PEMS07、PEMS08，由于单次预测开销大，每个数据集随机采样了 32 个测试点 (每个测试点是单个空间点和 12 个时间区间输入)，每次基于相同的 32 个点进行对比实验。

提示词设计：参考我搜集的相关论文，通常以单一探测器(空间点)的短期过去流量(如12个区间，每区间记录5分钟流量)及其相关信息(时间，星期等)为输入，要求预测该探测器的短期未来流量。

因此，我设计的提示词方案如下：

1. `plain`。关键数据只提供单空间点流量输入。
2. `neighbor`。在 `plain` 基础上，增加与该空间点相邻的所有空间点的流量输入。
3. `HA`。在 `plain` 基础上，提供这些时间区间在训练集上的历史平均流量。
4. `HA_neighbor`。结合了 `neighbor` 和 `HA`，即对相邻点流量也提供历史平均。

以 `HA_neighbor` 为例，设计出的提示词一个例子如下。

```
你需要完成交通流量预测任务。交通流量指的是一段时间内经过某个路口探测器的车辆的数目。探测器位于美国加州(California, USA)的中北部区域(North Central Area)。你有已知数据，为12个连续时间区间(每个时间区间的长度为5分钟)的流量。
当前探测器编号为290，探测器从2018-11-19 15:55:00到2018-11-19 16:55:00(Monday)的流量为:302, 326, 311, 314, 304, 342, 312, 335, 323, 308, 304, 312
这段时间以往的平均流量是346.3750, 350.2500, 359.7500, 354.2500, 338.7500, 350.6250, 344.3750, 325.2500, 334.1250, 343.8750, 333.8750, 340.5000，因此，输入流
量距离平均值的偏差是-44.3750, -24.2500, -48.7500, -40.2500, -34.7500, -8.6250, -32.3750, 9.7500, -11.1250, -35.8750, -29.8750, -28.5000。
与探测器290相邻的探测器编号为154, 289。这些探测器从2018-11-19 15:55:00到2018-11-19 16:55:00(Monday)的流量为:
探测器154的流量为514, 521, 522, 565, 523, 561, 446, 279, 297, 283, 347, 322。这段时间以往的平均流量是512.8750, 514.8750, 509, 530.2500, 520.6250, 495.1250, 
492.3750, 491.2500, 481.1250, 499.3750, 488.3750, 483.3750，因此，输入流量距离平均值的偏差是-210.8750, -188.8750, -198, -216.2500, -216.6250, -153.1250, -180.3750, -156.2500, -158.1250, -191.3750, -184.3750, -171.3750。
探测器289的流量为388, 409, 412, 402, 369, 427, 383, 416, 395, 380, 378, 377。这段时间以往的平均流量是420.3750, 416.7500, 425.3750, 414.6250, 419.3750, 420.7500, 418, 396.2500, 412.2500, 420, 413.8750, 419.1250，因此，输入流量距离平均值的偏差是-118.3750, -90.7500, -114.3750, -100.6250, -115.3750, -78.7500, -106, -61.2500, -89.2500, -112, -109.8750, -107.1250。
现在，请你预测接下来12个区间，即从2018-11-19 16:55:00到2018-11-19 17:55:00的流量。你只需要预测探测器290的流量。你要预测的12个区间的在过往的平均流量是335.3750, 344.2500, 353, 346.5000, 341.1250, 333.3750, 345.2500, 318.6250, 335.2500, 331.3750, 338.7500, 343.7500。
请你按照Python列表格式输出流量，保留4位小数。你只需要输出答案本身，无需输出任何计算过程和解释理由。
```

### 实验结果

在四个数据集下测试的实验结果如下：

```
PEMS03-32:
                mae      mape       rmse
Plain     32.979980  0.249627  46.975353
Neighbor  26.727194  0.204145  36.791534
HA        22.045837  0.150311  33.868702
HA_Nei    19.058632  0.140031  26.726738
HA_Nei(T) 18.892052  0.123374  28.649897

PEMS04-32:
                mae      mape       rmse
Plain     32.174080  0.184957  61.973930
Neighbor  26.929720  0.167282  54.225113
HA        29.372223  0.149416  57.545109
HA_Nei    15.777431  0.123573  32.505707

PEMS07-32:
                mae      mape       rmse
Plain     38.792011  0.129565  57.948433
Neighbor  40.558704  0.144437  63.940178
HA        39.854847  0.135642  66.284691
HA_Nei    20.265905  0.075539  28.247744

PEMS08-32:
                mae      mape       rmse
Plain     22.445910  0.132522  34.405945
Neighbor  22.497286  0.132565  34.148689
HA        21.692184  0.134507  33.723923
HA_Nei    18.505394  0.109718  30.051735
```

以 PEMS03 为例，对实验结果分析对比。结论如下：

1. 对比统计模型：不使用 LLM 的纯靠历史平均值(HA)的结果为

   ```
   MAE: 26.100666, MAPE: 0.268748, RMSE: 47.474395
   ```

   可以看到，所有的提示词设计都优于纯靠历史平均值预测。

2. 对比其他经典论文结果：

   <img src="img/image-20250815005056278.png" alt="image-20250815005056278" style="zoom:50%;" />

   可以发现，`Plain` 和 `Neighbor` 不如基准模型(GWNet, DCRNN 等)，但`HA` 和 `HA_neighbor` 优于一些基准模型，特别是 MAPE, RMSE 指标，能够达到当前的排名中上游水平。

3. 对比其他不带微调 LLM 的提示词工程的论文结果：

   <img src="img/image-20250815014900164.png" alt="image-20250815014900164" style="zoom:50%;" />

   发现 `HA` 和 `HA_neighbor` 优于 LLM-MPE，但不如上次组会讲的 LEAF。

   > 但对带模型微调的LLM，几乎全部都比不过它们。

4. 使用深度思考 `HA_nei(T)`，对比不使用 `HA_nei`，其差别统计学上不显著。

对 PEMS04、PEMS07、PEMS08 分析，其结果类似。

综上所述，在实验准确率上，提示词工程可以达到中上水平。

## 可行性分析

通常采用 6:2:2 划分数据集。如若测试一轮， 各测试集调用 API 次数为：

| 数据集   | PEMS03   | PEMS04   | PEMS07   | PEMS08   |
| -------- | -------- | -------- | -------- | -------- |
| 调用次数 | 5241x358 | 3398x307 | 5644x883 | 3571x170 |

### 时间成本

调用一次官方 Deepseek API，含网络时延和排队时延，若不使用深度思考，平均需要 7 秒。若使用深度思考，由于思维链非常长(5k tokens以上)，平均需要 5-15 分钟。

因此，如果调用 API 进行单个数据集的完整实验，假设不使用深度思考，分别需要的时间如下。

| 数据集   | PEMS03 | PEMS04 | PEMS07 | PEMS08 |
| -------- | ------ | ------ | ------ | ------ |
| 实验耗时 | 152天  | 84天   | 403天  | 49天   |

> 如果使用深度思考，设平均7分钟，即为7秒的60倍，以 PEMS03 为例，152天会变成42年。

因此，对 PEMS 数据集完整测试，不具备时间可行性。

> 由于时间关系：
>
> 1. 尚未测试多线程调用 API 是否会缩短耗时，以及是否可行。
> 2. 尚未测试组内是否有本地化部署满血版Deepseek或其他LLM的算力等资源。如果有，且本地化部署后每次调用 LLM 的速度可以比上述结果快<u>1-2个数量级</u>，那么具备实验的时间成本可行性。目前推测可能性低。

~~如果使用服务器部署 LLM，预估其耗时是否会有明显提升，计算如下。~~

~~组内服务器为8卡3090集群，可以求得单卡理论HBM为936GB/s，8卡为7.49TB/s。对FP32，单卡是35.58TFLOPS，故FP16为71.16TFLOPS，集群理论FP16为569.28TFLOPS。~~

~~根据Deepseek论文，满血版总参数671B，激活$N=37B$推理。隐藏维度7168，注意力头数128，使用混合精度FP16。设平均输入500tokens，输出100tokens。则预填充计算量为$2N\cdot500\approx3.7\times10^{13}$。预填充显存为$2N=7.4\times10^{10}$。求得 $TTFP=0.0748s$。解码总计算量$2N\cdot100$，显存同上。解得 $TPOT=0.0228s$。合计$0.0977s$。即约 $0.1s$ 可以完成推理。~~

~~显存开销：模型参数 $2N$~~

### 资金成本

Deepseek 官方给出的调用API报价为：

<img src="img/image-20250815015337354.png" alt="image-20250815015337354" style="zoom:50%;" />

不使用深度思考时，每次询问平均 71tokens输入(缓存命中)、343tokens输入(缓存不命中)、 72tokens输出。算得单次调用 API 需要 0.001元(根据时段，提示词方案不同，可能存在1-2倍误差，但数量级一样)。

根据上表，对测试集做完整实验，需要的总价为：(误差在1倍左右)

| 数据集   | PEMS03 | PEMS04 | PEMS07 | PEMS08 |
| -------- | ------ | ------ | ------ | ------ |
| 实验资金 | 1876元 | 1043元 | 4983元 | 607元  |

可见，如果调用 API，即使能解决时间问题，在资金上也不具备可行性。

> 如果使用深度思考，由于输出上万 tokens 一次的思维链，所以一次调用就可能需要 0.1 元。其价格等于不使用深度思考的约 100 倍。

**结论**：虽然使用提示词工程的实验准确率可以达到较优，但是在时间、资金等资源上严重不可行，不能直接应用于传统的交通流量预测任务。

> 如果使用 Deepseek 之外的其他 LLM API，其价格差别不会超过一个数量级。对时间开销，认为也应当不会超过一个数量级。

## 未来方向

针对可行性分析指出的问题，如果仍使用 LLM 提示词工程，有下面几个方向可以继续研究：

1. 换用更小的数据集。

   > 如：①每个区间5分钟粒度改成1小时乃至1天、数据集时间总长也进行裁剪。②不使用多个空间点，只使用一个空间点。③使用其他数据集，如出租车流量、人流量、其他时间(时空)序列预测任务。①②③ 有对应的论文。

2. 进行本地化部署，并达到一两个数量级的调用速度提升。

   > 不明确组里是否有足够算力资源，有待进一步实验确定是否可行。也可以换用其他 LLM 模型。

3. 把目前写的代码框架转化为专利产出。

   > 不确定当前已有成果的工作量/创新性是否足以作为一篇专利。

4. 直接取PEMS部分子集做测试集。

   > ①严谨性不足，可能与真实测试集结果不一样；②目前没有论文是这样做的。

5. 每次预测不只是输出单一空间点，而是输出全体数百个空间点。

   > ①LLM 的算量和输出量是一样的，可能耗时不会有显著差异；②预测精度可能大幅下降；③目前没有论文是这样做的。

如果不使用 LLM 继续研究，则考虑更换为研究其他内容，如交通流量预测的其他解法/场景。