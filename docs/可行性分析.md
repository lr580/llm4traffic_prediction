## 可行性分析

### API 调用

2025/8 版本，使用 Deepseek-chat，平均每次 API 调用耗费 7 秒 (包含网络和排队时延，下同)。

在 145 次询问中，使用了 10304 + 49826 tokens 输入，10440 tokens 输出。根据定价，算得 0.09-0.18 元(是否低峰期不同)。平均估计单价按 0.001 算。

则 PEMS03 的测试集为 5241x358；PEMS04 的 3398x307；PEMS07 的 5644x883；PEMS08 的 3571x170。即1e6数量级。按 7 秒一个算，分别需要 152 天，84 天，403 天，49 天。

使用深度思考 Deepseek-reasoner，调用一次 API 耗费 7-15 分钟。如果算 7 分钟，就是 60 倍，也就是 152天->24年。

所以，本机部署肯定是不可行的，哪怕不用深度思考，单线程预测，怎么跑都跑不完。只能调用现成的 API。

完整预测 PEMS，按 0.001 一次算，经费分别是 1876元，1043元，4983元，607元，约1万元，误差在一倍左右。

综上，无论是时间还是经费，都难以完整测试数据集。更不可能使用思维链。

### 本地部署

本地部署 Ollama，其他模型，在GTX3090下的推理速度：

- llama3.2:latest, 1-2s (输出格式可能不对, Plain MAPE 27.5%, HA 19.86%，其他结果很差，特别是纯 Neighbor)
- deepseek-coder-v2:16b 2-7s(根据提示词不同, 会报错，没跑完，输出格式可能不对)
- deepseek-v2:16b 2-5s(根据提示词不同, 会报错，没跑完，输出格式可能不对)
- qwen-v2.5:14b(2-3s,结果还不错)
- qwen-v2.5:7b(1.5-2s)
- qwen-v2.5:3b(1-1.5s)
- qwen-v2.5:1.5b (0.5-1s，但是感觉完全不能用)

qwen v2.5 14b

```
                mae      mape       rmse
Plain     30.260345  0.233959  42.954220
Neighbor  36.679924  0.262437  50.501282
HA        23.281046  0.176874  32.165596
HA_Nei    21.713377  0.158260  29.558413
```

qwen v2.5 7b

```
Plain     33.018703  0.230598  47.984669
Neighbor  32.003510  0.251705  42.949974
HA        25.473345  0.192144  35.987968
HA_Nei    25.349874  0.190306  34.613869
```

qwen v2.5 3b

```
                mae      mape       rmse
Plain     25.577576  0.186899  38.242775
Neighbor  44.792431  0.281817  72.165588
HA        23.300787  0.184814  32.613194
HA_Nei    26.878693  0.196762  35.406658
```

qwen v2.5 1.5b

```
                 mae      mape        rmse
Plain      97.148232  0.630173  138.297760
Neighbor  116.633118  0.665671  168.349121
HA         59.398026  0.426328   93.485176
HA_Nei     67.674538  0.427223  114.144173
```

